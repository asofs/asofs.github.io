---
layout: post
title:  "A Conversation on Technological Literacy"
date:   2022-09-27 12:00:00 -0600
author: "Anna-Sofia Lesiv"
header: "http://annasofia.xyz/assets/technolit.jpg"
---
![technolit](/assets/technolit.jpg)

I spent most this summer in New York City, as a member of Interact's residency cohort. I wanted time to develop my ideas on what I call "technological literacy" — or our growing need to understand the technological environment we live in.

There's a growing discrepancy between our reliance on technological systems and our understanding of them. Given the  complexity of the industrial and digital processes surrounding us, this is entirely understandable. However, in my view, delegating understanding is never a good thing, and it's best not to be blind to the inner workings of processes we interact with on a daily basis. Furthermore, by resolving to only be a passive consumer of technological goods means, in some ways, foregoing the ability to alter or manipulate the technological tools we use. Good writing about technology, it seems, is one of the missing pieces in this puzzle, without which, we're destined to continue walking blind in the modern maze of systems and gadgets. 

On August 13th, I hosted a conversation with some of my favorite writers; Nadia Asparouhova and Danny Crichton, joined by a few additional special guests to discuss these and many other! topics. I've transcribed the conversation below, because it's too good to not be shared.

**Anna-Sofia:** It's pretty obvious that the world is very much powered by technology and technological designs. The thing that's different and interesting about this today is that most of these designs, whether they are industrial processes, whether there are devices, the software we use — the inner workings of them are hidden, abstracted or literally invisible to the human eye.

Like if we think about the circuit logic in an iPhone, this is electron level stuff. So we can't even see it with our own eyes if we wanted to. All of computer engineering -- really anything digital, is built on abstractions. So it's much more difficult to see technologically and to intuit about the technologies that we use in our daily lives today than it was in the past.

This is the first passage from the book [The Elements of Computing Systems](https://www.amazon.com/Elements-Computing-Systems-Building-Principles/dp/0262640686), which is a book about how computers work. So it begins,

>Once upon a time, every computer specialist had a gestalt understanding of how computers worked. The overall interactions among hardware, software, compilers, and the operating system were simple and transparent enough to produce a coherent picture of the computer’s operations. As modern computer technologies have become increasingly more complex, this clarity is all but lost: the most fundamental ideas and techniques in computer science—the very essence of the field—are now hidden under many layers of obscure interfaces and proprietary implementations. An inevitable consequence of this complexity has been specialization, leading to computer science curricula of many courses, each covering a single aspect of the field. We wrote this book because we felt that many computer science students are missing the forest for the trees.”

So there's a sense in which maybe we're all kind of missing the forest for the trees in some way. I wrote, as part of this residency, three theses based on these ideas, and those were:

**1.** I think, technological literacy, like understanding the scientific, physical, mathematical concepts behind technological designs, will be increasingly important to retain agency in the world. So you can imagine, for example, economic or financial literacy is really important to how every responsible adult navigates the modern world. And so there's a claim to be made, or my claim is that going forward, having technological literacy is going to be very important to be able to orient yourself in the world.

**2.** Okay, second thing is all technological advancements create new problems. 

**3.** And the third is that the role of public writers should be to articulate those problems, and promote greater technological literacy through their writing.

So basically, what Nadia and Danny are doing really well. The other problem is, increasingly, it seems like there's fewer and fewer voices, institutions and publications that are telling stories about technology in these new ways, which is something I hope to dive into in our conversation today. 

What I think is most lacking from the discourse, is highlighted in following quote from the social critic, [Paul Goodman](https://en.wikipedia.org/wiki/Paul_Goodman), who says,

>Whether or not it draws on new scientific research, technology is a branch of moral philosophy, not of science.

I think that, in general, going forward, there should be more of an identity created between technology and culture.  

Technology is crucial in determining resource allocation, our habits, how we do things. I also think that technology is just a matter of design. It's a design with a lot of flexibility in the same way that an artwork is a design. And it's a reflection of a particular way of doing things. But there might be multiple expressions of that way of doing things. And so that's something that I also think is missing. 

The last thing is something that [Maran Nelson](https://twitter.com/marannelson), the founder of Interact pointed out to me, which is that if we accept that technology is art, we know that within the ecosystem of art, there's also an ecosystem of art critics that comment on the art. That's not really the case for technology, there's not really a culture or an ecosystem of critics like that. And is that maybe that something that will change? Or how do we think about that? Okay, that's enough from me.

Now, I've spoken with Danny and Nadia about these issues individually, but I'm really excited for the opportunity to speak about these themes for the first time as a group. To introduce them:

[Danny](https://twitter.com/DannyCrichton?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor) is like a polyglot, he studied math, computational science, and began a PhD in public policy. Danny was the managing editor of TechCrunch and now is the [head of editorial at Lux](https://www.getrevue.co/profile/lux_capital), where he is writing about the [complexities of our economic and technological world](https://www.dannycrichton.com/). 

[Nadia](https://twitter.com/nayafia) is someone that I really respect because she is really interested in the world of the unseen and the hidden. She's an independent researcher and writer, she published a really amazing report about the [unseen world of our digital infrastructure and who's building it](https://www.fordfoundation.org/work/learning/research-reports/roads-and-bridges-the-unseen-labor-behind-our-digital-infrastructure/). She later wrote a book about [open source software](https://press.stripe.com/working-in-public) and how it's built and maintained. Now, Nadia is focused on researching the [emergent philanthropic institutions](https://nadia.xyz/idea-machines) that tech wealth is creating and how it will be influencing the world. So really important questions which all coincide with tech, narrative storytelling, and institutions, which is basically the focus of our conversation.

**Danny Crichton:**
Thank you so much. Thank you, everyone, for coming.

**Anna-Sofia Lesiv:**
Yeah, thank you guys for being here. To open it up, I'm curious if you guys have any immediate reactions to the intro, otherwise, we can jump into a linear sequence of questions!

**Nadia Asparouhova:**
I was thinking about what technological literacy means today, and how that's sort of evolving because, in some senses, people need to know less about their computers, so I feel like some of these conversations have kind of fallen off.

But then, they're kind of missing this other side of like, yeah, maybe I don't need to know how to debug my computer anymore. But, one of the things that I always think about is, lack of technological literacy leads to fear of like, “the algorithm.” And the way people write about “the algorithm” in the media suggests this underlying fear or lack of understanding of how products work. That's just something that came to mind as you were talking.

**Danny Crichton:**
I was thinking this morning about how similar writing and software code is. I mean, they're really parallels right? They're quite interactive, and we seem to be entering a world in which we're increasingly doing hybrid technology. Software and hardware. Bio and tech, where it's not just enough to know the software, you actually have to know other fields of engineering and science in order to put it all together. And so, when we talk about literacy, even if you have software literacy, you don't necessarily have the complete literacy as to your first quote, from The Elements of Computing Systems, and to me that's a huge gap as we're entering the metaverse, VR, as more of our technologies are entering the physical world again. And I feel like we have to expand the definition of literacy quite a lot.

**Anna-Sofia Lesiv**
Okay, so maybe one good place to start is with this quote that 'technology is branch of moral philosophy.' To me, basically, any and every question about "should" resolves to some fundamental technology, in the sense that a technology is a mechanism for how something "should" be done. So I wanted to open that up to you guys and ask, what is the most valuable or operative framework that you use when looking at technology or when trying to critique it or ask questions about it? And another way of putting that is basically like, do you agree with this quote, that technology is a branch of moral philosophy? Or is it something else?

**Danny Crichton:**
I think it is a branch of moral philosophy. It's maybe more constrained than an open discussion of philosophy. Every technology offers capabilities — there's a range we oftentimes talk about in the government sector as dual use, right? There are technologies that can be used for good or for evil, and the user fundamentally gets to choose. So for instance, CRISPR, can be used to create vaccines to save lives, for COVID-19. At the same time, they can be used to optimize biological weapons, and, you know, create pathogens, that kill all of us. That said, I do think that there's, and this maybe is related to your tech critic piece — there hasn't been as much focus on the creators. I mean, the people who are building these technologies are shaping, in some ways, the destinies of how these things get used. 

So I would love to see both a better form of moral philosophy around technology a better framework and comprehensive view on it. I think that requires more tech critics, but also requires you to have the full swath of knowledge, everything from the limits of computation to the design constraints that an engineer, product manager or company faces to the psychologies of users. And unfortunately, that's a lot of fields all in one head. I don't know if anyone could ever pull it all off. But I agree with the premise that you're giving. I would love to see more of technology being considered a moral philosophy.

**Anna-Sofia Lesiv:**
So Nadia, when you were writing about open source, who did you see as the audience because obviously, it's quite niche. And there are limits to what you can do once you formed an opinion about something, as you mentioned, are you guys both writing for like this future generation of tech critics that will hopefully through your writing become more enlightened — and then talk to the engineers? Or do you envision a broader audience for yourselves?

**Nadia Asparouhova:**
I had a really specific decision to focus on developers and people at technology companies who are using open source software. Because yeah, I mean, this was a question early on, do we want this to be a more mainstream conversation? Do we want to try to get like, placements in mainstream publications? 

I think I asked myself, like, how do I need to change the argument in order for this to have mainstream coverage. Open source is usually covered as like, all about security vulnerabilities. It's a very narrow way of understanding what open source is because that's the only thing it's relevant to, you know, random person reading Washington Post or whatever. 

And then also, I got to ask myself, what is the impact if I achieve mainstream interest in this topic? Like, is that really going to change anything? I really care about impact. I don't want to just write stuff where random people go, "Oh, that's a nice story," and then they don't think about it anymore. 

If I really care about impacting open source, then I need to speak to the people that are actually consuming it. And when I first started, I just kind of assumed that if you're a software developer that uses open source, you understand a lot of the stuff that's going on. However, I quickly realized there was actually this huge gap. Just because you use open source does not mean you understand what is actually going on within open source projects. And it could actually be really useful to serve that translational gap.

**Danny Crichton:**
You'd be amazed how few topics people care about. Like, I'm always amazed — if you were to pull out all TechCrunch traffic, there are like three subjects. It's like Apple, Tesla and like Elon Musk's latest shenanigans are like 70% of all attention that stories get. 

It's just the reality that a Tesla story will do 100 times better than almost any startup. Right? And if you think about it, that makes sense. Like, no one's ever heard of the startup. Why would I care about something I have never heard of before, which is why you will oftentimes see in the headlines like Sequoia-backed or YC-backed because these are signals, you know, signifiers that we should care about it. 

If you really want to do pathbreaking original work in technology, whether it's criticism, whether it's a new field, whether it's you know, science that hasn't been covered before, I mean, there's not an audience. There's no one who cares. There's no one who's searching for it. 

So that was one of the challenges I faced. I covered a lot of the US-China trade politics, which, thanks to events in the world has become much more interesting than when I started and there were like six writers covering that and, you know, we were focused on open source technologies and 5G back in like 2017. I used to get no views. Then, thanks to politics and everything, we got more and more attention.

I really think that as a writer, you have to constantly be thinking, not just *who is your audience*, because oftentimes, there is no audience, you have to be thinking *who can I convince* and get them to say things like, "I really have to get into this", "I want to read multiple things", "I want to read a book", "I want to maybe subscribe to the newsletter", because you are filling in a gap that they have. Much in the way that a technology product fills, you know, needs or gaps that folks have as consumers. 

As a writer, I think of it as, what are the intellectual gaps? In my own newsletter, [Securities](https://www.getrevue.co/profile/lux_capital), that gap is interdisciplinary focus on technology, science, finance, and geopolitical complexity, connecting dots between a lot of different fields, all simultaneously, things that we've seen in the news that are usually written separately, and just saying, like, "Look, all these are intertwined and connected for various reasons". Because to me, so much of modern press is very siloed and verticalized.

**Anna-Sofia Lesiv:**
Yeah, well, this really, I think this explodes the conversation into the direction I'd like to take it. 

I wanted to ask you guys — what exactly are these gaps that are not being talked about or written about? What are the ways that technology is not being written about as a form or style question that you would like to see more of?

**Nadia Asparouhova:**
I mean, I'm biased based on the stuff that I'm looking at now. 

But I think there's been a shift from the era of startup building and wealth accumulation to, how do we now grapple with our newfound power as tech and think about our place in society?

I think that transition is slowly happening, like you see things happening on the ground that suggests that is happening within tech, but then I don't feel like that has quite entered the mainstream narrative yet. 

So that's like the topic that I'm personally interested in. But yeah, I still think that the broader conversations around, what is the role of technology in my life? and how do I grapple with it? 

I think the technology critics that are writing about those kinds of things, right now, tend to write all in the same way. I feel like it's all the same sort of critique. The critics exist, but they're all kind of saying the same thing. If you can always predict, like I said, you could just automatically generate ...

**Danny Crichton:**
GPT-3

**Nadia Asparouhova:**
It's so focused on social media, it's always focusing on these very specific areas of technology. To me, good critiques don't start out with this end goal in mind. It's more about starting by observing what is going on. Start by just trying to explain what is happening and then slowly form a thesis through that. I just don't feel like I see that kind of nuanced critique of tech right now.

**Danny Crichton:** 
I'll give an example. Carolyn Chen, has a new book that just came out, I want to say three or four months ago, called Work Pray Code. Good title. She focuses on the translation of East Asian Buddhism, Zen Buddhism, from East Asia into California in the 1960s with the countercultural movement and then how it morphed into the modern day — like mindfulness, wellness, particularly corporate-directed mindfulness programs like at Google and other large tech companies. And she talks about how  this very nonmaterial religion, *because Buddhism is all about accumulating wealth*, has transformed places like large tech companies into this culture where, at the beginning of every meeting at some Google, you take five minutes as a breathing exercise. It's like, "Here's this Buddhism moment ... and now we're going to talk about how to optimize the ads." She was the first critic I saw that was offering a sociological, a different, angle. I take that as an example, since I'm always really interested in all these intersections. 

I'm also interested in the built environment, and the built environment that is starting to reach end of life. If we look around us, you know, our sewers, our transportation systems, airports, our power grid, a lot of it was built in the post-war era. A lot of it was built for 50-70 year horizons, a lot of it's coming to end of life and needs to be replaced. 

And as a generation, my generation of millennials, or Gen Z, or even Gen X, none of us have ever been part of these systems and replacing the systems in our built environment. And so as an example, like one of the more successful essays I did, as a writer at TechCrunch, was a focus on the New York City subways and how they brought wireless and WiFi into stations. I thought that this was going to be a really niche subject, no one would care. And then I interviewed Transit Wireless, the company that did it. They spent seven years putting WiFi and wireless into the stations and what the story ended up becoming was just like the impossibility of what it takes to get a signal into these stations. Namely, they have to deal with rats, they have to deal with water, terrorism, people peeing on them. I was talking to the CEO and he was like, "You know, milspec, or military spec, like doesn't even come close". Because like no one pees on tanks. It's not something that the Defense Department normally worries about. But if you pee on one of these antennas, it shorts out. And so it ended up being a really successful article. I can see the numbers. And I think it's a good example that it is possible to go beneath the surface and to show how things work. 

The challenge has been getting away from the glare of a couple of core technologies. Social media is obviously one. There are like three books on making subways, and there are like 1000 books on how social media is eating your mind. And I don't know how to redirect. 

This is the challenge with audiences. Ultimately, there's buyers for these books. The reason you keep seeing "social media is terrible" books is because there's a huge market of readers who want to read, "oh my God, my brain is being fried". But I then that's where I go back to the audience development. I really want to create more audiences. We're all in a market driven publishing environment. We need more audiences that are curious about how we built the built environment, and how do we replace it, and how do we not lose what we already have and make it better going forward for the next generation?

**Nadia Asparouhova:**
I do wonder, is it realistic to create a market for that? Going back to my own standard on directly impacting people's lives — one reason why the social media narratives have been so successful is partly because it's fun scare tactics or whatever, and they've worked really well. But it's also because like, everyone deals with social media every single day, and it *is* infecting their minds every day. So it is directly impactful to think about it and have a conversation about it. 

And, there is a little bit of the like, "isn't it so cool how this thing works?" and everyone goes, "yeah, it's really interesting how this works," and then they go back to their lives. So I'm trying to think of how to draw that line from these more nuanced conversations. Like where do you see the impacts of that on someone's life?

**Danny Crichton** 
This is an insight I've been thinking about and I haven't pushed the limit too far — but this is the first generation that widely codes. If you step back and look over the last 30-40 years, computer science used to be in really tight ivory tower circuits. At one point, you could actually meet every person who could code a computer, like in a room this size.

I learned the code in elementary school and middle school, and it was really hard. I bought books, you went to Barnes and Noble and got like *How to Code C++*, like this was prior to Stack Overflow, all the tutorials, all the modern ways to learn, and now I think with Roblox, Minecraft, a bunch of other platforms, there's this openness, where people by default, maybe even if not at a very proficient level, are learning basic if statements, code structures, control structures, functions, at ridiculously early ages. So part of me is asking, maybe there's an audience for a lot of the stuff around technology today. 

If you look at people who are 20, going into their 30s, there are now millions and millions of people who can at least understand the rudimentary basics of coding to understand how digital technologies work — which didn't exist before. I actually think that this is a huge gap for publishers. I just don't think people are realizing that actually, all these people that speak the same language could have a similar base of knowledge to build upon. So I call it generation code.

**Anna-Sofia Lesiv:**
It's really interesting, because, on the one hand, when computers first came about, they were massive, so expensive to build, they literally were only used for like large scale scientific projects to replicate a sense of scale — and then Moore's Law kicked in and now everyone has like two or more computers, literally on their person all the time. And no one really knew what to do with that. 

There was this incredible programmer who wrote memoirs of her experience programming, Ellen Ullman. And she basically wrote, 'The computer's gonna enter our body, our experience. It'll be in our veins, but we don't have the literacy with which to use it. The first computers were designed with the idea End User Programming. So if you wanted to use it, you have to program it yourself to do stuff for you.

However now, similarly to the programs that Ellen Ullman built for scale, require, design thinking which assumes that the user is an idiot. You want the end user to not be able to mess up the system in any way. They have screens where all they can do is click "okay". The system tells you how to do it, you can't tell the system how to do it. So to the extent that there's an identity between technology and culture, culture is a way of doing things or the habits that you form.

What we lose, when we don't have this kind of literacy is like, let's say they have a daily habit or a way that we like to do things, now, it's really difficult for people to make the computer do it that way. Instead, they have to do the task the way the computer does it. So like, where I think this literacy could be more useful, is for people to have more of a sense of control over their tools. 

**[Omar Rizwan](https://twitter.com/rsnous):**
I think one of the hopes is that there's some kind of latent demand. Like, it's like one of those things where it's like, why should we build a bike lane here — because nobody bikes here. Well, once you build a big bike lane, people will bike there. Or like, why should we build a bridge here? Nobody crosses this river because they don't swim. Sometimes there's latent demand that appears when you build the infrastructure.

**Nadia Asparouhova:**
I think I've been going in the opposite direction, where people are becoming both more and less technologically literate and that like, I don't see us reverting back to a world where people are deeply engaged with programming their tools.

With Roblox and Minecraft, they're not even really like programming — technically speaking — they're not coding, but it's the same behavior, and I feel like the thing that we're seeing more is everyone just instantly being able to see their whole world as programmable in some shape or form which is teaching people agency or something.

**Omar Rizwan:** 
I think the question is like, if you have these different systems that people are using, like Roblox, or Instagram, or like the web or whatever, like, what are the externalities of people learning to use that system? Like what other stuff do they end up being able to do — because they learn how to make webpages or learn how to use Roblox?

I think there is like a difference of like, if you know how to use Instagram, you spend all your time on Instagram. There's kind of like a cap on like, what does that lead you to really think? If you learn to program an Apple II, I think that like actually kind of is an introduction into some kind of broader world of programming in a way that's useful for society.

**Danny Crichton:**
I mean, in this modern world, we also have all the no-code tools and all the no-code platforms. And so at some point, we have to ask, like, what is programming, right? If programming is If-Then statements, control statements, functions, inputs, outputs, like, you know, if you've designed a dashboard with Retool that takes some data process, displays it in different ways — like that is *visual* programming, but it *is* programming. 

Like — this also counts!

If you're using your technology, that's allowing you to do what you want to do. It's no different than like, if you've coded your own smartphone systems, right? When I walk into a room and the lights turned on, that is a form of programming. It wasn't designed to do that. You chose to do it, you just, you know, developed a flowchart of decision making that goes into it. 

To go back to the original question, I think the ideal is a format where design is sort of in layers. It can do everything autonomously, I can do it visually, at a very simple level, I can also get into the code and get an open source layer and actually change everything and how it works. Because most of our technologies are fairly locked down somewhere in that stack, right? I can't go into the hardware of my iPhone and change, like how it communicates to a cell tower. I also can't change much of the software either, like it's actually hidden.

**Omar Rizwan:** 
One of the things that's interesting is like, even for stuff that's nominally open source — this is one of the points we made at Dynamicland — has anybody read the Google Chrome source code? Has anybody changed the Google Chrome source code? I would bet that the answer is no. Like in this room, like it's open source ... you can read it. But you know, I think there's like a practical side to that.

**Anna-Sofia Lesiv:**
I think what's interesting, like, Danny, to your point, you can't change how your device communicates with the cell tower. 

That's something that Omar and I were talking about, this notion of like, how easy is it to creatively destroy stuff like in the digital medium? Like, is it easier or harder than in the physical world? Some say in the digital world, you have so much more leverage, you know, like, I do one change, and it reaches a million users. On the flip side, you can just tear a building down and renew it. And if I wanted to change, let's say, the network architecture of the Internet, or one of these, like fundamental standards that everyone now is using, like, it's really difficult to do. And I think realizing how difficult that is, is something that most people like don't understand, because there's this prevailing idea that like, "Oh, you get so much leverage in the digital medium."

**Danny Crichton:**
Well, one positive direction, as an example, if you look at semiconductors right now, there's a massive push to actually open source core technologies around chip design. So for instance, last week, Google will now in the next couple of years, allow anyone on the internet to basically create chips at an actual fab, they'll print them, they'll etch them, and they'll mail them to you.

**Omar Rizwan:**
I'm waiting for mine in the mail.

**Danny Crichton:**
And like chips are one of those pieces where you don't have any control over the chip in your phone, your computer but for the first time ever, like in decades, we're actually gonna be able to run full fab runs of custom chips, which means the x86 model could be changed. The risk processing models need to change. We might have 30 different designs in the future and instruction sets. Whereas today, we only have like three or four — on mobile one, on desktop two.

**Omar Rizwan:**
[Skywater](https://www.ibj.com/articles/skywater-project-critical-in-microelectronics-push) is one of the fabs that's doing this, and then I think another one is [Global Foundries](https://gf.com/).

**Danny Crichton:** 
And they're using a technology company called [efabless](https://efabless.com/open_shuttle_program). They announced it last year. But as our software is getting more and more locked down, there's extreme concern around the hardware side of things. From the government, from national security, from a lot of people in electrical engineering, and that's what we're seeing like with with [RAN](https://en.wikipedia.org/wiki/Radio_access_network) and [Open RAN](https://www.youtube.com/watch?v=Ma-NBj_1e-0) technology, 5G is being opened up, semiconductor design is being opened up, there's a real movement underway on the hardware side to like, re-allow tinkering. And I think this connects to the broader right to repair movement that's going on.

**Nadia Asparouhova:**
I just wonder how widespread it's all going to become. Because the reason why I think things are getting harder to change in the digital world is because we have these complex webs of interdependencies.

A friend recently jailbroke his Nintendo Switch or whatever, but he said, the problem is — 'I can't do any software updates anymore'. So even if you have your bespoke version of hardware or bespoke version of software then like, you're missing out.

It feels like there will be those options for people that want them, but the common user experience is still going to be like more and more these harder-to-change systems, because you're depending on something.

**Danny Crichton:**
One of the other challenges is that the fabs are going out of the 130 nanometers designs, and our chips today are five nanometers going towards three nanometers. So we're talking like microscopic size. We're constrained not just by software and those interfaces, but it's actually a much more physical constraint, which is the speed that these things have to run on.I was talking about playing with your 5G antenna. The reality is, your 5G antenna is this amazingly optimized piece of equipment that is designed to — with almost no battery usage whatsoever, communicate gigabytes to the cloud instantaneously. So you can tinker, but almost all your tinkers are gonna be worse than what's already out there which is why consumers struggle with this so much.

We see the same thing with buildings and building design. It's more expensive today to build a skyscraper than it was 100 years ago. It's not because we're somehow worse at building skyscrapers. It's actually the opposite. We're far, far better. Skyscrapers are amazingly better today than they were 100 years ago. They're better for heat and cooling. They're better for movement of people, they require less pillars. We're actually better with better materials. But that means that the costs are higher. 

And so we have these constraints where, you want to tinker, but if you actually want people to use this stuff in the real world, you're competing, ultimately, against what else is out there, and the optimal stuff is always going to win.

**Danny Crichton:**
I've given up the idea that all of our technology will be legible. It's just not feasible anymore.

Every single one of our technological systems has gotten more complicated because it's under more stress. It's under more constraints. You know, the power grid, go back to energy, is not that complicated, right? Like if you actually go back to the fundamentals of electricity, it doesn't actually take much to learn. The problem is the modern grid which requires 100% uptime with no variance in the amount of power that's coming out, has backups and redundancies. All that is what adds complication to the legibility of these systems. Look at your phone — just the lightning port adapter! Go into a lightning port and I think there's 32 channels, 26 are data, 6 are power, those were actually built on other standards from USB and elsewhere. Those have compression standards that are designed so that you can fit as much data through that tube as fast as possible.

To give a more tangible example, look at the car today versus what you could do 100 years ago. 100 years ago, you could get a car in the mail that was built with 500 parts and a manual in like the early 1900s. Today, there are 600 microchips in a car. This is why our cars are all delayed because of supply chains. I just I think if you want heated and cooling seats, with satellite radio, GPS built in, you know, an entertainment system in the dashboard, at a certain point, all this adds up and you say that it's just not legible.

Like, there's just no way to understand how all this connects. Now, you could zoom in, and I think in most cases are principles. You know, there are fundamentals in most of these fields that if you were to go into say, 5G — I've been to like the NYU 5G Center — there's like four core technologies and you if you kind of understand what's going on with each of them, you'll mostly understand what's happening. But like even that, is that legibility is that literacy? I don't know.

**Anna-Sofia Lesiv:** 
But how does that view connect with the right to repair movement? Because if you're repairing something, you kind of need to know how to repair it.

**Danny Crichton:**
I think the right to repair movement is going the complete wrong direction. I don't think anything is repairable. I think there's some stuff, like a John Deere tractor, that should be, you know, ideally, more repairable. But we're talking very small chips, like battery replacement and a phone. I don't know if you've seen how this battery gets fit into an iPhone. You need specialists. It's just not something where you're gonna be able to do it yourself. 

**[Kevin Kwok](https://twitter.com/kevinakwok):**
So, as a follow up, if you believe that it's not full legibility that we should have, is there some degree that you think we should have? And if not, is there something else that you think is important, instead of legibility? 

**Anna-Sofia Lesiv:**
I will wager an answer to this. You know, you could say nothing is legible because it's so complex, and we can't see it ... you could also say that, like when humans began travelling great distances, and discovered that the world was round, you know, from a first person perspective, you can't visualize that. But eventually, we developed maps of the world. And then we learned that we're actually in a solar system, and actually, in a galaxy, actually a universe. And we have maps of those things, even though we can't see them with our eyes, we can kind of represent them where we have a mental model, where we can visualize the system. And I think what's lacking is a mental model for a lot of the interfaces and interactions between different technologies, these types of things. Like I think that kind of work somehow hasn't been done. We don't have maps of our technological ecosystem.

**Danny Crichton:**
I think a huge part of it is trust. I will never understand how huge parts of my technology work. And I have a computer science background.

I wish I could figure out all the security and like the crazy levels of detail that requires like all these systems to work, but I can't. I have to trust other specialists' expertise going into this. You know, you look at every part of the stack. There are PhDs who do that particular field, someone who has spent 10-12 years to like, learn Ethernet. And I'm really not exaggerating. There are parts where it's like, at this point in the USB standard, like you need a PhD in order to even get up to speed on how this technology works. And I just have to trust that! I think that's actually one of the big tensions in technology today. If you look at crypto as like trustless and moving towards a model where we don't have to trust other people, to the fact that in a technology sense, we actually have to trust people all the time. None of us can actually observe all of our code, nothing is verifiable. Our phones, today, I think want us to but it's like 200 million lines of code. You can't even physically read the code that is on this Phone anymore. Like it's just not possible. And so once we're in a world in which you can't read everything, it's fundamentally going to be illegible, right? Like at some, at some scale. So maybe we need maps? Maybe we need principles?

But is just knowing that there are four key principles to 5G enough to understand enough? Is that competent enough? I couldn't build it. If all the technology in the world disappeared tomorrow, I'm back in a cave.

**Nadia Asparouhova:**
To me, what's more important is teaching this skill of believing that you have agency over technology. That's the big dividing line that I see between people that are afraid of technology versus excited. Because I don't know anything about 5G or whatever, but I'm not afraid of it.

I would wager that the vast majority of the general population just think that technology happens to them. Like when something doesn't work, they're just like, "Oh no, it's like attacking me!", right? Instead of being like, "Okay, maybe I don't know what's going on, but I can try to understand it." It's a two way conversation — I can engage with this thing, I can figure out how to get around it. That sense that you can program your world or that the world is inherently programmable — makes you feel that you have agency over the world. I feel like that is like an under-discussed character trait. Like, when I think about teaching technological literacy, that's what I want to teach.

**[Shrey Jain](https://twitter.com/shreyjaineth):**
Yeah, before we were saying how hard it is to program the digital world, like have autonomy over standards — but I was curious to know, what do you think about standards that people have, like, let's say, Internet standards, or like podcast standards, or RSS, or healthcare standards like FHIR? I wonder why it still feels so constrained when in practice, that's not the case with many early stage companies.

**Omar Rizwan:**
Well, for one thing — I think there's a difference between, if you're a big tech company, and you have the audience already, you control the demand, then you can change the standards.

The web standard is not controlled by like the Web Consortium, it's controlled by the browser vendors. And then like, the standard is just whatever the browser vendors want to do. I think that is true. I think that if you're an upstart, and you're trying to do something new, I think that the barrier to entry imposed by like, what if you want to make a new web browser, you have to implement this, like, gigantic web standard that nobody has ever succeeded in doing. Nobody's ever written a new web browser in like, 20 years? 

And I think there are a lot of things like that. Suppose you want to make a new computer, okay? Like, how are you gonna support network cards, how you're gonna support graphics cards? How are you gonna do all this stuff? And you need to do that stuff to meet the expected level of functionality that the users expect. And I think that imposes extremely onerous barriers to entry for new technology.

**Danny Crichton:**
I think I like Facebook moving to Graph QL from like JSON or something like that, you know, if you control both the app and like the server, and there's an API that's well organized, you can control both sides. It's actually really easy to change.

But then you look at like, COBOL installations at large banks — the mainframes that run our entire financial system, and everyone always says, like, "why is it still running off of 1960s computers" and like, this is why your balances are always pending for 24 hours.

I used to live in Korea. You couldn't get an ATM transaction from midnight to 3AM every night because all banks shut down for those three hours to actually process all the transactions so that they would turn back on and like 3 or 4 AM. 

So at bars, you either had to pay prior to 12 or you had to wait until 3 AM to pay off your bill. Like, it's so hard to remove some systems because they do get to such levels of complexity. 

Like actually, there's no one alive today who understands them anymore. I actually think that these systems are widely available if you look at nuclear power plants, large parts of the grid.

Have you ever seen like the signalling systems in the subway? It's all literally like vacuum tubes, like it's a mechanical signalling system. There's no digital technology whatsoever. No one knows how this operates. Because it was installed by people two generations ago. And they didn't teach their kids, and certainly not their grandkids. 

So to me, we're actually surrounded by systems that no one understands. In which case, you get into a Chesterton's fence kind of principle of like, what do you do with the technology that you don't understand? One answer is you should just rip it out because you can't replace it anyway, or you can't fix it ... but it's working.

**Anna-Sofia Lesiv:**
So I really want to get back to Nadia's point about basically like, what is the role of the individual and how do we make them feel that they have agency in the world again.

I also really want to add something on to what you just said, Danny. We *are* surrounded by systems that we don't understand. And in many cases, probably there's like, no one that understands them. And I've been thinking about this a lot. In particular, I was prompted to think about this by [Jonathan Blow](https://www.youtube.com/watch?v=pW-SOdj4Kkk), who actually [Keegan](https://twitter.com/keegan_mcnamara) introduced me to. So he has this thesis essentially that software is getting worse. Software engineers in general are getting worse, they're getting less knowledgeable, and everything runs on software. And everything is really old software. And at some point, people won't know how to fix old software and old software, which controls, a lot of stuff will just like break or stop working, and we won't know how to fix it. 

He has this great analogy. Our civilization is, indeed very technologically advanced — but so was the Roman civilization. When Roman civilization perished, that knowledge perished with them and Europe entered into a period of Dark Ages. 

So, it's happened before, you know, it could potentially happen again. And from that perspective, there really might be some cause for concern.

**Nadia Asparouhova:**
That's a really good plot for a sci fi.

**Anna-Sofia Lesiv:**
It's interesting — the literary world is obsessed with apocalyptic scenarios. After all, when modern technology is wiped out — could we rebuild? In most cases, you can't. You need large scales of social organization to even be able to, like, do a lot of these things. You already need the computer to ...

**Omar Rizwan:**
make the computer. Yeah.

**Anna-Sofia Lesiv:**
All right, I really wanted to bring it back to this question of personal agency.

Every process is just so interconnected or depends on something else. We just said that we can't survive in a world without technology. We depend on technology for literally everything. 

It does feel like we're babies that are nannied by this technological state. So what is the role of the human in this kind of world? I think it's a very unanswered and unclear question. So how do we encourage people to feel like they're in control?

**Danny Crichton:**
Has anybody read the short story from E. M. Forster, *[The Machine Stops](https://www.cs.ucdavis.edu/~koehl/Teaching/ECS188/PDF_files/Machine_stops.pdf)*?  

**Nadia Asparouhova:**
Yes!

**Danny Crichton:**
It's a really short story. If you haven't read it, you can read it in about 15 minutes before the end of this.

But basically, Forster is writing about a society where folks are, I believe in caves, if I recall correctly? You're sort of enveloped in like an entirely machine interface with the world. You communicate through the machine. This was written 100 years ago. And all of a sudden, one day, the machine stops. People are forced to figure out how to survive, how to get food, how to, you know, like, what happens when the internet goes down? There's no DoorDash. And there's no Whole Foods delivery, like — "Oh my God, I don't even know where to go!"

This question never animates me as much as it does some people. I feel like I have a lot of agency, which either means I'm deluded, or I have agency.

I don't feel like I'm locked into my devices. As a writer, and as someone who really focuses on deep work, I can go a day without my devices. Yesterday I spent 12 hours editing a doc — I didn't look at email. I mean, I use a computer — I could use a typewriter I suppose?

But I don't feel like I was ever locked into my devices. I guess I was using electricity, so there's some level of civilizational technology I needed in order to survive, but I feel like I have a high degree of agency. 

Now, I do know folks who are very addicted to their phones. I feel like they certainly are lacking some level of agency, because they literally just can't, like, let go. I do look at some of these Pew studies that show like 85 or 90% of people are scrolling through social media as they fall asleep. I don't even have my phone in my bedroom. I've never had my phone in my bedroom! I just find that strange. At least for me, I feel like I control the technology. I can choose when to use it. I can choose what to install on it. I am measured in how I use my attention on all these devices.

**Nadia Asparouhova:**
Same boat, yeah. 

To take this in a slightly different direction — I was thinking about this in relation to anti-natalism as a byproduct of social movements where people that say, "I don't think I want to have kids because the world is just clearly going to hell in a handbasket, and climate change is gonna ruin the world — why should we bring children into this world?" And I have a really hard time relating to that sentiment, which is, you know, it's widespread, it's not unusual. 

And I really can't relate to that at all. I think it does come down to this feeling where if you believe that the world is happening to you and you have kids, then they're just sort of the victims of whatever is happening to the environment.

**Omar Rizwan:**
It's like I'm creating more subjects versus creating more agents.

**Nadia Asparouhova:** 
Right. Whereas, I'm excited to have kids for the exact opposite reason! I'm like, yeah — go fix climate change, go save the world! So yeah, it's a totally different relationship.

[**Lisa Wehden** ](https://twitter.com/lisawehden)
I just wanted to push you on that. Our technology now is going to influence the physical infrastructure at this juncture in which we have to rebuild our physical environment and therefore, we're going to use technology to redesign housing, electricity, climate change — there's a lot of different opportunities here. 

As a result, I think this new segment of people are going to have to become much more technologically sophisticated. Do you feel like that is a trend in the right direction in terms of helping people regain agency over technology? As I hear you both speaking now, maybe you have technological literacy when you have agency over your devices, and that's what this means?

**Danny Crichton:**
I'll connect a couple of dots. I think the West in particular focuses on individual agency as an ability to control the system. And I think the answer is we don't, right?

**Anna-Sofia Lesiv:**
On that note, it is impossible to predict where things are going. If you look at chaos theory, or the butterfly effect, which gives the illustrative example of a butterfly flapping its wings and eventually causing a tornado — we have no idea like, what action will impact the system in what way just because it's now such a complicated system, there are so many factors.

**Danny Crichton:**
So, I think we have individual agency over our devices, all your personal technology.

But at the societal level, I have no control over the winds and the fires burning down whole parts of California, or that Europe is under drought and there's no water.

To me, there's an opportunity for collective agency and societal agency or team based agency. Which is to say, I don't know how to grow food most effectively on a piece of land, but, as a group, if we're actually gonna continue to produce the food supplied and meet the needs of another 2 billion people who are joining the plant in the next 30-40 years, we have to continue to be more productive on all land than we are even today, right? After all the optimizations over thousands of years, we still need to extract another 25% out of that while also using less land.

And I think the path is basically what (Lisa) sort of indicated, which is really raised the bar. Going from monoculture with a single combine that's going over all corn and picking it up to saying you're gonna need 8 or 10 plants read-in properly, using machine learning, using vision to quickly adapt based on soil conditions and hydrology, and that's gonna require going from a brute force, physical labor model to one where you're using technology as an appendage to a group of people trying to sustainably manage a piece of land. And to me, there is collective action, there is collective agency, which is to say, you can raise the bar and create more complexity.

Complexity is good, by the way. That's another piece, I don't think we've actually brought it up — and I've been complaining about it, but like, complexity is fundamentally the definition of civilization. It's going from creating niches for different people, different specializations. You know something I don't therefore we both benefit because we're offering both of our knowledge to the economy. 

So the only way I think we actually survive the future in this transition to new infrastructures is precisely what you've indicated which is, we have to join in teams, we're going to specialize even further, and we're gonna have to communicate, we're gonna actually have to spend more time on it.

Today, one of the most magical things about our civilization is that less than 1% of people are in farming, and less than 1% of people work in energy production. Right? If you think about it — the two things we need are food and fuel — less than 1% for both!

The other 98% of us get to do everything else in this society — culture and computer science, and anything we want to do, but that initial number will go up. And in some ways, it'll be okay, because a lot of those jobs are actually going to be much more interesting. They're going to be a lot more engaging. They're gonna require a lot more skill and thinking. Some of us may actually be farmers someday, and I would not be surprised.

**Omar Rizwan:**
I mean, I think something interesting in what Lisa said implied this relationship between literacy or understanding and agency. 

One of the issues that I have with (Anna-Sofia's) initial framing of technological literacy is, is it actually our goal just to have people understand things? Like, is it our goal to just educate people in some set of knowledge or facts? Does that constitute literacy? Or do you have to be able to make something or replicate some kind of thing? Literacy in the domain of text means you can both read and write. You're able to produce some sort of artifact, and that's kind of the test of literacy.

I think that's kind of like what (Lisa) is getting at — that producing some kind of new technology is what constitutes technological literacy there.

**Anna-Sofia Lesiv:**
All right, I have one final question. And then I think we'll wrap it up. 

Okay, we are writers, we write words. Is this a dying technology? Is this the right way to communicate our ideas? When we think about encoding information for posterity, how should we think about the media?

**Nadia Asparouhova:**
I mean, yeah, I'm a traditionalist here. 

I feel like people have been saying blogs are dying for a long time, they say long form is dying. There was that whole time people thought video was gonna be the next thing. I think this probably reflects my own biases, but I'm extremely text heavy and text dependent. I'm really bad at audio, I'm really bad at video.

I write everything in like a text editor, so it's just the way that I think. In all these years that everyone keeps proclaiming the death of long form, the death of writing, it continues to persist, it grows. I mean, with Substack, like, you know, it became a thing again. It just finds new ways to continue to live on. 

There's just no substitute for it. Visuals just induce a different way of thinking about a medium than the written word does. Like when you look at words, it stimulates your own imagination and stimulates you to think about things in different ways. I feel like when I watch a movie or something, it's this passive relationship or it doesn't stimulate my own creativity. So yeah, I'm just sort of a words maximalist. I think writing is gonna live on forever. And I reject all attempts to innovate there.

**Danny Crichton:**
I agree 100% with everything just said. 

I would add in, I think writing is somewhat unique among the media that we see in our world today, which is still very individual. You as a person can write an article — by yourself. Whereas with video, I mean, you have to have camera crews and editors and sound engineers and mixers. And, suddenly that ethereal vision goes away. 

I think the magic of writing even today is the range of styles are so broad, the topics are so unique, and that comes from the last point — it's very decentralized. I can do what I want to do, you can do what you want to do, and I don't have to get 20 other people to agree. I don't have to raise a million dollars to go produce a 30-40 minute documentary in order to produce at the scale that readers would be interested in.

It's like what my math professor used to say, "the best part about math is all you need is a pencil and a piece of paper." That's true as much in writing as it is in math.

**Anna-Sofia Lesiv:**
Great. Well, thank you all so much. And thank you everybody for coming and asking fantastic questions and participating. This was wonderful.

![talk](/assets/talk.jpg)